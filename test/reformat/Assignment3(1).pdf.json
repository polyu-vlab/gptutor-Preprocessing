[
    {
        "page 0 of /Volumes/Projects/PolyU_GPTutoring/Document_Loader/test/assets/Assignment3(1).pdf": "COMP4434 Big Data Analytics\nAssignment 3\nPolyU, Hong Kong\nInstructor: HUANG Xiao\nLogistics: You should submit your solutions through Learn@PolyU (Blackboard). The deadline is\nMonday April 8, 11:55 PM. I will no accept submission from any other channels except Blackboard.\nThese are the best exercises that could help you be well prepared for quizzes. Thus, please work inde-\npendently.\nProblem 1 (3 points)\nAssume that we have a large number of files that store the weighted edges of a huge directed graph.\nEach one of them contains content in the format as follows.\n(1, 5, 0.3),\n(2, 3, 0.7),\n(6, 3, 0.5),\n(2, 6, 0.8), ...\n(4, 7, 0.2),\n(7, 2, 0.1),\n(9, 3, 0.9),\n(1, 7, 0.4), ...\n(8, 3, 0.8),\n(9, 1, 0.3),\n(3, 4, 0.4),\n(4, 5, 0.2), ...\n...\nAs we could see, each file contains many lines. Each line contains a set of triples, i.e., (source id, target\nid, weight). Our goal is to calculate the sum of weights of all edges of each vertex (including incoming\nand outgoing edges).\n(a) Write pseudo-code for map worker, including the (key, value) pairs of the input and output.\n(b) Write pseudo-code for reduce worker, including the (key, value) pairs of the input and output.\n1\n"
    },
    {
        "page 1 of /Volumes/Projects/PolyU_GPTutoring/Document_Loader/test/assets/Assignment3(1).pdf": "Problem 2 (5 points)\nWe have four text files as follows, storing the student grades of four subjects.\n[{\"column 1 'math.txt' of row  1 'math.txt'\": 'math.txt', \"column 2 'physics.txt' of row  1 'math.txt'\": 'physics.txt', \"column 3 'chemistry.txt' of row  1 'math.txt'\": 'chemistry.txt', \"column 4 'art.txt' of row  1\n'math.txt'\": 'art.txt'}, {\"column 1 'math.txt' of row  2 'James, 91\\nJohn, 89\\nRobert, 72\\nMichael, 81\\nDavid, 76\\nMary, 79\\nLinda, 63\\nSusan, 67\\nLisa, 76'\": 'James, 91\\nJohn, 89\\nRobert,\n72\\nMichael, 81\\nDavid, 76\\nMary, 79\\nLinda, 63\\nSusan, 67\\nLisa, 76', \"column 2 'physics.txt' of row  2 'James, 91\\nJohn, 89\\nRobert, 72\\nMichael, 81\\nDavid, 76\\nMary, 79\\nLinda, 63\\nSusan,\n67\\nLisa, 76'\": 'James, 57\\nJohn, 78\\nRobert, 68\\nMichael, 71\\nDavid, 79\\nMary, 69\\nLinda, 79\\nSusan, 76\\nLisa, 74', \"column 3 'chemistry.txt' of row  2 'James, 91\\nJohn, 89\\nRobert, 72\\nMichael,\n81\\nDavid, 76\\nMary, 79\\nLinda, 63\\nSusan, 67\\nLisa, 76'\": 'James, 78\\nJohn, 92\\nRobert, 68\\nMichael, 91\\nDavid, 77\\nMary, 74\\nLinda, 89\\nSusan, 87\\nLisa, 92', \"column 4 'art.txt' of row  2\n'James, 91\\nJohn, 89\\nRobert, 72\\nMichael, 81\\nDavid, 76\\nMary, 79\\nLinda, 63\\nSusan, 67\\nLisa, 76'\": 'James, 67\\nJohn, 89\\nRobert, 88\\nMichael, 87\\nDavid, 68\\nMary, 79\\nLinda, 94\\nSusan,\n78\\nLisa, 91'}]\nOur goal is to calculate the total scores of students in all four subjects. (In practice, we could have more\nstudents and more subjects.)\n(a) What are the relationships between MapReduce and Hadoop?\n(b) Write pseudo-code for map worker, including the (key, value) pairs of the input and output.\n(c) Write pseudo-code for reduce worker, including the (key, value) pairs of the input and output.\n(d) What are the concrete inputs and outputs of your implemented mapper and reducer when process-\ning the above four text files?\n2\n"
    }
]